{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6097d79a",
   "metadata": {},
   "source": [
    "# ZAF202310_Book_Recommendation_Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1269798d",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f31823",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb82b96c",
   "metadata": {},
   "source": [
    "## Business Segments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec5414",
   "metadata": {},
   "source": [
    "## Data\n",
    "1. Book Recommendation System - [Link](https://www.kaggle.com/datasets/arashnic/book-recommendation-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f2672a",
   "metadata": {},
   "source": [
    "## Papers\n",
    "- Collaborative Filtering Recommender Systems - [Link](https://www.researchgate.net/publication/200121027_Collaborative_Filtering_Recommender_Systems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e41533",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4764b521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38bbc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\AppData\\Local\\Temp\\ipykernel_7880\\2526589295.py:1: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_df = pd.read_csv('data/Books.csv')\n"
     ]
    }
   ],
   "source": [
    "# Reading the csv files\n",
    "books_df = pd.read_csv('data/Books.csv')\n",
    "ratings_df = pd.read_csv('data/Ratings.csv')\n",
    "user_df = pd.read_csv('data/Users.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b32194",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b43ce43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging data into one dataframe\n",
    "book_ratings_df = ratings_df.merge(books_df, on='ISBN')\n",
    "user_book_ratings_df = book_ratings_df.merge(user_df, on='User-ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1f18aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>tyler, texas, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2313</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>5</td>\n",
       "      <td>Flesh Tones: A Novel</td>\n",
       "      <td>M. J. Rose</td>\n",
       "      <td>2002</td>\n",
       "      <td>Ballantine Books</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/034545104X.0...</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2313</td>\n",
       "      <td>0812533550</td>\n",
       "      <td>9</td>\n",
       "      <td>Ender's Game (Ender Wiggins Saga (Paperback))</td>\n",
       "      <td>Orson Scott Card</td>\n",
       "      <td>1986</td>\n",
       "      <td>Tor Books</td>\n",
       "      <td>http://images.amazon.com/images/P/0812533550.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0812533550.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0812533550.0...</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2313</td>\n",
       "      <td>0679745580</td>\n",
       "      <td>8</td>\n",
       "      <td>In Cold Blood (Vintage International)</td>\n",
       "      <td>TRUMAN CAPOTE</td>\n",
       "      <td>1994</td>\n",
       "      <td>Vintage</td>\n",
       "      <td>http://images.amazon.com/images/P/0679745580.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0679745580.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0679745580.0...</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2313</td>\n",
       "      <td>0060173289</td>\n",
       "      <td>9</td>\n",
       "      <td>Divine Secrets of the Ya-Ya Sisterhood : A Novel</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>1996</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>http://images.amazon.com/images/P/0060173289.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060173289.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060173289.0...</td>\n",
       "      <td>cincinnati, ohio, usa</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031131</th>\n",
       "      <td>276442</td>\n",
       "      <td>2862749796</td>\n",
       "      <td>7</td>\n",
       "      <td>Le Huit</td>\n",
       "      <td>Katherine Neville</td>\n",
       "      <td>2002</td>\n",
       "      <td>Le Cherche Midi</td>\n",
       "      <td>http://images.amazon.com/images/P/2862749796.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/2862749796.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/2862749796.0...</td>\n",
       "      <td>genève, genève, switzerland</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>276618</td>\n",
       "      <td>3788097000</td>\n",
       "      <td>5</td>\n",
       "      <td>Ludwig Marum: Briefe aus dem Konzentrationslag...</td>\n",
       "      <td>Ludwig Marum</td>\n",
       "      <td>1984</td>\n",
       "      <td>C.F. MÃ¼ller</td>\n",
       "      <td>http://images.amazon.com/images/P/3788097000.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/3788097000.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/3788097000.0...</td>\n",
       "      <td>stuttgart, \\n/a\\\"., germany\"</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031133</th>\n",
       "      <td>276647</td>\n",
       "      <td>0553571001</td>\n",
       "      <td>0</td>\n",
       "      <td>Christmas With Anne and Other Holiday Stories:...</td>\n",
       "      <td>L. M. Montgomery</td>\n",
       "      <td>2001</td>\n",
       "      <td>Starfire</td>\n",
       "      <td>http://images.amazon.com/images/P/0553571001.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0553571001.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0553571001.0...</td>\n",
       "      <td>arlington heights, illinois, usa</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031134</th>\n",
       "      <td>276647</td>\n",
       "      <td>0689822294</td>\n",
       "      <td>10</td>\n",
       "      <td>Heaven (Coretta Scott King Author Award Winner)</td>\n",
       "      <td>Angela Johnson</td>\n",
       "      <td>1998</td>\n",
       "      <td>Simon &amp;amp; Schuster Children's Publishing</td>\n",
       "      <td>http://images.amazon.com/images/P/0689822294.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0689822294.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0689822294.0...</td>\n",
       "      <td>arlington heights, illinois, usa</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031135</th>\n",
       "      <td>276660</td>\n",
       "      <td>0583307841</td>\n",
       "      <td>8</td>\n",
       "      <td>ROBOT RACE (MICRO ADV 6)</td>\n",
       "      <td>David Antony Kroft</td>\n",
       "      <td>1985</td>\n",
       "      <td>HarperCollins Publishers</td>\n",
       "      <td>http://images.amazon.com/images/P/0583307841.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0583307841.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0583307841.0...</td>\n",
       "      <td>singapore, n/a, singapore</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031136 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User-ID        ISBN  Book-Rating  \\\n",
       "0         276725  034545104X            0   \n",
       "1           2313  034545104X            5   \n",
       "2           2313  0812533550            9   \n",
       "3           2313  0679745580            8   \n",
       "4           2313  0060173289            9   \n",
       "...          ...         ...          ...   \n",
       "1031131   276442  2862749796            7   \n",
       "1031132   276618  3788097000            5   \n",
       "1031133   276647  0553571001            0   \n",
       "1031134   276647  0689822294           10   \n",
       "1031135   276660  0583307841            8   \n",
       "\n",
       "                                                Book-Title  \\\n",
       "0                                     Flesh Tones: A Novel   \n",
       "1                                     Flesh Tones: A Novel   \n",
       "2            Ender's Game (Ender Wiggins Saga (Paperback))   \n",
       "3                    In Cold Blood (Vintage International)   \n",
       "4         Divine Secrets of the Ya-Ya Sisterhood : A Novel   \n",
       "...                                                    ...   \n",
       "1031131                                            Le Huit   \n",
       "1031132  Ludwig Marum: Briefe aus dem Konzentrationslag...   \n",
       "1031133  Christmas With Anne and Other Holiday Stories:...   \n",
       "1031134    Heaven (Coretta Scott King Author Award Winner)   \n",
       "1031135                           ROBOT RACE (MICRO ADV 6)   \n",
       "\n",
       "                Book-Author Year-Of-Publication  \\\n",
       "0                M. J. Rose                2002   \n",
       "1                M. J. Rose                2002   \n",
       "2          Orson Scott Card                1986   \n",
       "3             TRUMAN CAPOTE                1994   \n",
       "4             Rebecca Wells                1996   \n",
       "...                     ...                 ...   \n",
       "1031131   Katherine Neville                2002   \n",
       "1031132        Ludwig Marum                1984   \n",
       "1031133    L. M. Montgomery                2001   \n",
       "1031134      Angela Johnson                1998   \n",
       "1031135  David Antony Kroft                1985   \n",
       "\n",
       "                                          Publisher  \\\n",
       "0                                  Ballantine Books   \n",
       "1                                  Ballantine Books   \n",
       "2                                         Tor Books   \n",
       "3                                           Vintage   \n",
       "4                                     HarperCollins   \n",
       "...                                             ...   \n",
       "1031131                             Le Cherche Midi   \n",
       "1031132                                C.F. MÃ¼ller   \n",
       "1031133                                    Starfire   \n",
       "1031134  Simon &amp; Schuster Children's Publishing   \n",
       "1031135                    HarperCollins Publishers   \n",
       "\n",
       "                                               Image-URL-S  \\\n",
       "0        http://images.amazon.com/images/P/034545104X.0...   \n",
       "1        http://images.amazon.com/images/P/034545104X.0...   \n",
       "2        http://images.amazon.com/images/P/0812533550.0...   \n",
       "3        http://images.amazon.com/images/P/0679745580.0...   \n",
       "4        http://images.amazon.com/images/P/0060173289.0...   \n",
       "...                                                    ...   \n",
       "1031131  http://images.amazon.com/images/P/2862749796.0...   \n",
       "1031132  http://images.amazon.com/images/P/3788097000.0...   \n",
       "1031133  http://images.amazon.com/images/P/0553571001.0...   \n",
       "1031134  http://images.amazon.com/images/P/0689822294.0...   \n",
       "1031135  http://images.amazon.com/images/P/0583307841.0...   \n",
       "\n",
       "                                               Image-URL-M  \\\n",
       "0        http://images.amazon.com/images/P/034545104X.0...   \n",
       "1        http://images.amazon.com/images/P/034545104X.0...   \n",
       "2        http://images.amazon.com/images/P/0812533550.0...   \n",
       "3        http://images.amazon.com/images/P/0679745580.0...   \n",
       "4        http://images.amazon.com/images/P/0060173289.0...   \n",
       "...                                                    ...   \n",
       "1031131  http://images.amazon.com/images/P/2862749796.0...   \n",
       "1031132  http://images.amazon.com/images/P/3788097000.0...   \n",
       "1031133  http://images.amazon.com/images/P/0553571001.0...   \n",
       "1031134  http://images.amazon.com/images/P/0689822294.0...   \n",
       "1031135  http://images.amazon.com/images/P/0583307841.0...   \n",
       "\n",
       "                                               Image-URL-L  \\\n",
       "0        http://images.amazon.com/images/P/034545104X.0...   \n",
       "1        http://images.amazon.com/images/P/034545104X.0...   \n",
       "2        http://images.amazon.com/images/P/0812533550.0...   \n",
       "3        http://images.amazon.com/images/P/0679745580.0...   \n",
       "4        http://images.amazon.com/images/P/0060173289.0...   \n",
       "...                                                    ...   \n",
       "1031131  http://images.amazon.com/images/P/2862749796.0...   \n",
       "1031132  http://images.amazon.com/images/P/3788097000.0...   \n",
       "1031133  http://images.amazon.com/images/P/0553571001.0...   \n",
       "1031134  http://images.amazon.com/images/P/0689822294.0...   \n",
       "1031135  http://images.amazon.com/images/P/0583307841.0...   \n",
       "\n",
       "                                 Location   Age  \n",
       "0                       tyler, texas, usa   NaN  \n",
       "1                   cincinnati, ohio, usa  23.0  \n",
       "2                   cincinnati, ohio, usa  23.0  \n",
       "3                   cincinnati, ohio, usa  23.0  \n",
       "4                   cincinnati, ohio, usa  23.0  \n",
       "...                                   ...   ...  \n",
       "1031131       genève, genève, switzerland  62.0  \n",
       "1031132      stuttgart, \\n/a\\\"., germany\"   NaN  \n",
       "1031133  arlington heights, illinois, usa  13.0  \n",
       "1031134  arlington heights, illinois, usa  13.0  \n",
       "1031135         singapore, n/a, singapore  15.0  \n",
       "\n",
       "[1031136 rows x 12 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First look at data\n",
    "user_book_ratings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e2c8ffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of unique Book-Titles and creating a new column\n",
    "book_dict = {}\n",
    "for idx, book in enumerate(user_book_ratings_df['Book-Title'].unique()):\n",
    "    book_dict[book] = idx\n",
    "user_book_ratings_df['Book-ID'] = user_book_ratings_df['Book-Title'].map(book_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "69317909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dictionary of unique User-IDs and creating a new column\n",
    "user_dict = {}\n",
    "for idx, user in enumerate(user_book_ratings_df['User-ID'].unique()):\n",
    "    user_dict[user] = idx\n",
    "user_book_ratings_df['New-User-ID'] = user_book_ratings_df['User-ID'].map(user_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c62da1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Final DF to use\n",
    "final_df = user_book_ratings_df[['New-User-ID', 'Book-ID', 'Book-Rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5bb45fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>New-User-ID</th>\n",
       "      <th>Book-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031131</th>\n",
       "      <td>92102</td>\n",
       "      <td>241066</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031132</th>\n",
       "      <td>92103</td>\n",
       "      <td>241067</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031133</th>\n",
       "      <td>92104</td>\n",
       "      <td>241068</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031134</th>\n",
       "      <td>92104</td>\n",
       "      <td>241069</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031135</th>\n",
       "      <td>92105</td>\n",
       "      <td>241070</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1031136 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         New-User-ID  Book-ID  Book-Rating\n",
       "0                  0        0            0\n",
       "1                  1        0            5\n",
       "2                  1        1            9\n",
       "3                  1        2            8\n",
       "4                  1        3            9\n",
       "...              ...      ...          ...\n",
       "1031131        92102   241066            7\n",
       "1031132        92103   241067            5\n",
       "1031133        92104   241068            0\n",
       "1031134        92104   241069           10\n",
       "1031135        92105   241070            8\n",
       "\n",
       "[1031136 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final DF look\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeed21f",
   "metadata": {},
   "source": [
    "## 3. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec4426b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing data into X and y sets\n",
    "X = pd.DataFrame({'user-id': final_df['New-User-ID'],\n",
    "                 'book-id': final_df['Book-ID']})\n",
    "y = final_df['Book-Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72993ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (1031136, 2)\n",
      "y shape: (1031136,)\n",
      "Number of unique users: 92106\n",
      "Number of unique books: 241071\n"
     ]
    }
   ],
   "source": [
    "# Checking X and y shape and number of unique users and books\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "n_users = X['user-id'].nunique()\n",
    "n_books = X['book-id'].nunique()\n",
    "print(f\"Number of unique users: {n_users}\")\n",
    "print(f\"Number of unique books: {n_books}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1715d",
   "metadata": {},
   "source": [
    "## 4. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0eda55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from itertools import zip_longest\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F \n",
    "from torch.optim.lr_scheduler import _LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "22fbca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a class for reviews iterator\n",
    "class ReviewsIterator:\n",
    "    \n",
    "    def __init__(self, X, y, batch_size=32, shuffle=True):\n",
    "        \n",
    "        X, y = np.array(X), np.array(y)\n",
    "        \n",
    "        if shuffle:\n",
    "            index = np.random.permutation(X.shape[0])\n",
    "            X, y = X[index], y[index]\n",
    "            \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.n_batches = int(math.ceil(X.shape[0] / self.batch_size))\n",
    "        self.current_ = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        return self.next()\n",
    "    \n",
    "    def next(self):\n",
    "        if self.current_ >= self.n_batches:\n",
    "            raise StopIteration()\n",
    "        k = self.current_\n",
    "        self.current_ += 1\n",
    "        bs = self.batch_size\n",
    "        return self.X[k*bs: (k+1)*bs], self.y[k*bs: (k+1)*bs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9d6bf681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to yield X and y in batches\n",
    "def batches(X, y, bs=32, shuffle=True):\n",
    "    for xb, yb in ReviewsIterator(X, y, bs, shuffle):\n",
    "        xb = torch.LongTensor(xb)\n",
    "        yb = torch.FloatTensor(yb)\n",
    "        yield xb, yb.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f021f5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[16729,  2219],\n",
      "        [  485,  9416],\n",
      "        [  774,  9340],\n",
      "        [17401,  9217]])\n",
      "tensor([[0.],\n",
      "        [7.],\n",
      "        [0.],\n",
      "        [6.]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for x_batch, y_batch in batches(X, y, bs=4):\n",
    "    print(x_batch)\n",
    "    print(y_batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "db2e1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a class for building Embedding Net\n",
    "class EmbeddingNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, n_users, n_books, \n",
    "                n_factors=50, embedding_dropout=0.02,\n",
    "                hidden=10, dropouts=0.2):\n",
    "        super().__init__()\n",
    "        hidden = get_list(hidden)\n",
    "        dropouts = get_list(dropouts)\n",
    "        n_last = hidden[-1]\n",
    "        \n",
    "        def gen_layers(n_in):\n",
    "            nonlocal hidden, dropouts\n",
    "            assert len(dropouts) <= len(hidden)\n",
    "            \n",
    "            for n_out, rate in zip_longest(hidden, dropouts):\n",
    "                yield nn.Linear(n_in, n_out)\n",
    "                yield nn.ReLU()\n",
    "                if rate is not None and rate > 0.:\n",
    "                    yield nn.Dropout(rate)\n",
    "                n_in = n_out\n",
    "                \n",
    "        self.u = nn.Embedding(n_users, n_factors)\n",
    "        self.b = nn.Embedding(n_books, n_factors)\n",
    "        self.drop = nn.Dropout(embedding_dropout)\n",
    "        self.hidden = nn.Sequential(*list(gen_layers(n_factors * 2)))\n",
    "        self.fc = nn.Linear(n_last, 1)\n",
    "        self._init()\n",
    "        \n",
    "    def forward(self, users, books, minmax=None):\n",
    "        features = torch.cat([self.u(users), self.b(books)], dim=1)\n",
    "        x = self.drop(features)\n",
    "        x = self.hidden(x)\n",
    "        out = torch.sigmoid(self.fc(x))\n",
    "        if minmax is not None:\n",
    "            min_rating, max_rating = minmax\n",
    "            out = out*(max_rating - min_rating + 1) + min_rating - 0.5\n",
    "        return out\n",
    "    \n",
    "    def _init(self):\n",
    "        def init(m):\n",
    "            if type(m) == nn.Linear:\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.01)\n",
    "                \n",
    "        self.u.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.b.weight.data.uniform_(-0.05, 0.05)\n",
    "        self.hidden.apply(init)\n",
    "        init(self.fc)\n",
    "        \n",
    "def get_list(n):\n",
    "    if isinstance(n, (int, float)):\n",
    "        return [n]\n",
    "    elif hasattr(n, '__iter__'):\n",
    "        return list(n)\n",
    "    raise TypeError('layers configuraiton should be a single number or a list of numbers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bf5a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a class for Cyclic LR Scheduler\n",
    "class CyclicLR(_LRScheduler):\n",
    "    \n",
    "    def __init__(self, optimizer, schedule, last_epoch=-1):\n",
    "        assert callable(schedule)\n",
    "        self.schedule = schedule\n",
    "        super().__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.schedule(self.last_epoch, lr) for lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "35cb9dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for calculating cosine value\n",
    "def cosine(t_max, eta_min=0):\n",
    "    \n",
    "    def scheduler(epoch, base_lr):\n",
    "        t = epoch % t_max\n",
    "        return eta_min + (base_lr - eta_min)*(1 + math.cos(math.pi*t/t_max))/2\n",
    "    \n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "db641be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting X and y into train and validation states\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "datasets = {'train': (X_train, y_train), 'val': (X_valid, y_valid)}\n",
    "dataset_sizes = {'train': len(X_train), 'val': len(X_valid)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c0707615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining min and max ratings\n",
    "minmax = final_df['Book-Rating'].min(), final_df['Book-Rating'].max()\n",
    "minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "df95c3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiing the network\n",
    "model = EmbeddingNet(\n",
    "    n_users=n_users, n_books=n_books, \n",
    "    n_factors=150, hidden=[500, 500, 500], \n",
    "    embedding_dropout=0.05, dropouts=[0.5, 0.5, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e009fd0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss improvement on epoch: 1\n",
      "[001/015] train: 12.0935 - val: 12.3695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "wd = 1e-5\n",
    "bs = 32 \n",
    "n_epochs = 15\n",
    "patience = 10\n",
    "no_improvements = 0\n",
    "best_loss = np.inf\n",
    "best_weights = None\n",
    "history = []\n",
    "lr_history = []\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net.to(device)\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = optim.Adam(net.parameters(), lr=lr, weight_decay=wd)\n",
    "iterations_per_epoch = int(math.ceil(dataset_sizes['train'] // bs))\n",
    "scheduler = CyclicLR(optimizer, cosine(t_max=iterations_per_epoch * 2, eta_min=lr/10))\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    stats = {'epoch': epoch + 1, 'total': n_epochs}\n",
    "    \n",
    "    for phase in ('train', 'val'):\n",
    "        training = phase == 'train'\n",
    "        running_loss = 0.0\n",
    "        n_batches = 0\n",
    "        batch_num = 0\n",
    "        for batch in batches(*datasets[phase], shuffle=training, bs=bs):\n",
    "            x_batch, y_batch = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            # compute gradients only during 'train' phase\n",
    "            with torch.set_grad_enabled(training):\n",
    "                outputs = model(x_batch[:, 0], x_batch[:, 1], minmax)\n",
    "                loss = criterion(outputs, y_batch)\n",
    "                \n",
    "                # don't update weights and rates when in 'val' phase\n",
    "                if training:\n",
    "                    optimizer.step()\n",
    "                    scheduler.step()\n",
    "                    loss.backward()\n",
    "                    lr_history.extend(scheduler.get_lr())\n",
    "                    \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        stats[phase] = epoch_loss\n",
    "        \n",
    "        # early stopping: save weights of the best model so far\n",
    "        if phase == 'val':\n",
    "            if epoch_loss < best_loss:\n",
    "                print('loss improvement on epoch: %d' % (epoch + 1))\n",
    "                best_loss = epoch_loss\n",
    "#                 best_weights = copy.deepcopy(net.state_dict())\n",
    "                torch.save(model, 'model.pt')\n",
    "                no_improvements = 0\n",
    "            else:\n",
    "                no_improvements += 1\n",
    "                \n",
    "    history.append(stats)\n",
    "    print('[{epoch:03d}/{total:03d}] train: {train:.4f} - val: {val:.4f}'.format(**stats))\n",
    "    if no_improvements >= patience:\n",
    "        print('early stopping after epoch {epoch:03d}'.format(**stats))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d3ea806",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ad692a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingNet(\n",
       "  (u): Embedding(92106, 150)\n",
       "  (b): Embedding(241071, 150)\n",
       "  (drop): Dropout(p=0.05, inplace=False)\n",
       "  (hidden): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=500, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (4): ReLU()\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=500, out_features=500, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Dropout(p=0.25, inplace=False)\n",
       "  )\n",
       "  (fc): Linear(in_features=500, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
